{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from xml.etree.ElementTree import fromstring \n",
    "import shutil\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old data and database\n",
    "\n",
    "if os.path.exists(\"data\"):\n",
    "    shutil.rmtree(\"data\")\n",
    "if os.path.exists(\"ufc_database.db\"):\n",
    "    os.remove(\"ufc_database.db\")\n",
    "os.makedirs(\"data\")\n",
    "\n",
    "# # Create required directories\n",
    "# directories = ['./data/fighters/', './data/git/']\n",
    "# for directory in directories:\n",
    "#     os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# # Define CSV files and their columns\n",
    "# csv_files = {\n",
    "#     './data/event_urls_sherdog.csv': ['Event_URL'],\n",
    "#     './data/fighter_id_sherdog.csv': ['Fighter', 'Fighter_ID'],\n",
    "#     './data/event_data_sherdog.csv': ['Event Name', 'Event Location', 'Event Date', \n",
    "#                                       'Fighter 1', 'Fighter 2', 'Weight Class', \n",
    "#                                       'Winning Fighter', 'Winning Method', \n",
    "#                                       'Winning Round', 'Winning Time', 'Referee'],\n",
    "#     './data/fighter_info.csv': ['Fighter', 'Nickname', 'Birth Date', 'Nationality', \n",
    "#                                 'Hometown', 'Association', 'Weight Class', 'Height', \n",
    "#                                 'REACH', 'STANCE', 'Wins', 'Losses', 'Win_Decision', \n",
    "#                                 'Win_KO', 'Win_Sub', 'Loss_Decision', 'Loss_KO', \n",
    "#                                 'Loss_Sub', 'Sherdog URL', 'BFO URL']\n",
    "# }\n",
    "\n",
    "# # Ensure CSV files exist and have headers\n",
    "# for file_path, columns in csv_files.items():\n",
    "#     if not os.path.exists(file_path):\n",
    "#         pd.DataFrame(columns=columns).to_csv(file_path, index=False)\n",
    "\n",
    "# # Function to download GitHub data\n",
    "# def download_github_files():\n",
    "#     files = [\"ufc_event_details.csv\", \"ufc_fight_results.csv\", \n",
    "#              \"ufc_fight_stats.csv\", \"ufc_fighter_tott.csv\"]\n",
    "#     base_url = \"https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/main/\"\n",
    "#     save_path = \"./data/git/\"\n",
    "\n",
    "#     for file in files:\n",
    "#         response = requests.get(base_url + file)\n",
    "#         if response.status_code == 200:\n",
    "#             with open(os.path.join(save_path, file), 'wb') as f:\n",
    "#                 f.write(response.content)\n",
    "#         else:\n",
    "#             print(f\"Failed to download {file}\")\n",
    "\n",
    "# # Execute file download\n",
    "# download_github_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrape 7 URLs...\n",
      "Processing URL 1/7\n",
      "Processing URL 2/7\n",
      "Processing URL 3/7\n",
      "Processing URL 4/7\n",
      "Processing URL 5/7\n",
      "Processing URL 6/7\n",
      "Processing URL 7/7\n",
      "Updated event URLs saved.\n",
      "Broken URLs removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5f67a30bcd47f38f289a7ce40ab505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scraping Events:   0%|          | 0/696 [00:00<?, ?Event/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sherdog: Event URLs\n",
    "# event_urls_sherdog.csv\n",
    "\n",
    "urls = [\n",
    "    'https://www.sherdog.com/organizations/Ultimate-Fighting-Championship-UFC-2/recent-events/1',\n",
    "    'https://www.sherdog.com/organizations/Ultimate-Fighting-Championship-UFC-2/recent-events/2',\n",
    "    'https://www.sherdog.com/organizations/Ultimate-Fighting-Championship-UFC-2/recent-events/3',\n",
    "    'https://www.sherdog.com/organizations/Ultimate-Fighting-Championship-UFC-2/recent-events/4',\n",
    "    'https://www.sherdog.com/organizations/Ultimate-Fighting-Championship-UFC-2/recent-events/5',\n",
    "    'https://www.sherdog.com/organizations/Ultimate-Fighting-Championship-UFC-2/recent-events/6',\n",
    "    'https://www.sherdog.com/organizations/Ultimate-Fighting-Championship-UFC-2/recent-events/7'\n",
    "]\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0\"\n",
    "]\n",
    "headers = {\"User-Agent\": random.choice(user_agents)}\n",
    "df = pd.read_csv('./data/event_urls_sherdog.csv') if os.path.isfile('./data/event_urls_sherdog.csv') else pd.DataFrame(columns=['Event_URL'])\n",
    "existing_urls = set(df['Event_URL'])\n",
    "\n",
    "print(f\"Starting to scrape {len(urls)} URLs...\")\n",
    "for i, url in enumerate(urls, 1):\n",
    "    print(f\"Processing URL {i}/{len(urls)}\")\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        specific_div = soup.find('div', {'class': 'single_tab', 'id': 'recent_tab'})\n",
    "        if specific_div:\n",
    "            new_urls = [a.get('href') for a in specific_div.find_all('a', itemprop='url') if a.get('href') and a.get('href') not in existing_urls]\n",
    "            df = pd.concat([df, pd.DataFrame(new_urls, columns=['Event_URL'])], ignore_index=True)\n",
    "    except requests.RequestException:\n",
    "        print(f\"Failed to process URL {i}\")\n",
    "        pass\n",
    "\n",
    "df.to_csv('./data/event_urls_sherdog.csv', index=False)\n",
    "print(\"Updated event URLs saved.\")\n",
    "\n",
    "# Remove Broken URL's \n",
    "urls_to_delete = {\n",
    "    \"/events/UFC-233-Ultimate-Fighting-Championship-233-72021\",\n",
    "    \"/events/UFC-Fight-Night-97-Lamas-vs-Penn-90890\",\n",
    "    \"/events/UFC-176-Aldo-vs-Mendes-2-37609\",\n",
    "    \"/events/UFC-151-Jones-vs-Henderson-25809\"\n",
    "}\n",
    "df = pd.read_csv(\"./data/event_urls_sherdog.csv\")\n",
    "df = df[~df[\"Event_URL\"].isin(urls_to_delete)]\n",
    "df.to_csv(\"./data/event_urls_sherdog.csv\", index=False)\n",
    "print(\"Broken URLs removed.\")\n",
    "\n",
    "# Event URLs \n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "]\n",
    "df = pd.read_csv('./data/event_urls_sherdog.csv')\n",
    "df['Event_URL'] = \"https://sherdog.com\" + df['Event_URL'].astype(str)\n",
    "event_dates = []\n",
    "with requests.Session() as session:\n",
    "    session.headers.update({\"User-Agent\": random.choice(user_agents)})\n",
    "    with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "        # futures = {executor.submit(session.get, url, {\"User-Agent\": random.choice(user_agents)}, 30): url for url in df['Event_URL']}\n",
    "        futures = {executor.submit(lambda url: session.get(url, headers={\"User-Agent\": random.choice(user_agents)}, timeout=30), url): url for url in df['Event_URL']}\n",
    "        for future in tqdm(as_completed(futures), total=len(df['Event_URL']), desc=\"Scraping Events\", unit=\"Event\"):\n",
    "            url = futures[future]\n",
    "            try:\n",
    "                response = future.result()\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    event_date_meta = soup.find('meta', itemprop='startDate')\n",
    "                    event_dates.append(event_date_meta['content'].strip() if event_date_meta else None)\n",
    "                else:\n",
    "                    event_dates.append(\"Error\")\n",
    "            except requests.exceptions.RequestException:\n",
    "                event_dates.append(\"Error\")\n",
    "df['Event Date'] = event_dates\n",
    "df.to_csv('./data/event_urls_sherdog.csv', index=False)\n",
    "print(\"Event dates appended successfully.\")\n",
    "print(f\"Total number of rows including the header in event_urls_sherdog.csv: {len(df)}\")\n",
    "print(f\"Column names: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sherdog: Event Data\n",
    "# event_data_sherdog.csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}\n",
    "urls_df = pd.read_csv('data/event_urls_sherdog.csv')\n",
    "all_data = []\n",
    "def fetch_event_data(url, session):\n",
    "    full_url = f'https://sherdog.com{url}' if not url.startswith('http') else url\n",
    "    event_data = []\n",
    "    try:\n",
    "        with session.get(full_url, headers=headers) as response:\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                event_name = soup.find('span', itemprop='name').text.strip()\n",
    "                event_location = soup.find('span', itemprop='location').text.strip()\n",
    "                event_date = soup.find('meta', itemprop='startDate')['content'].strip()\n",
    "                main_event_fighters = soup.find_all('div', class_='fighter')\n",
    "                if main_event_fighters:\n",
    "                    fighter1 = main_event_fighters[0].find('span', itemprop='name').text.strip()\n",
    "                    fighter2 = main_event_fighters[1].find('span', itemprop='name').text.strip()\n",
    "                    fighter1_id = main_event_fighters[0].find('a', itemprop='url')['href'].split('-')[-1]\n",
    "                    fighter2_id = main_event_fighters[1].find('a', itemprop='url')['href'].split('-')[-1]\n",
    "                    weight_class = soup.find('span', class_='weight_class').text.strip()\n",
    "                    winning_fighter = fighter1  \n",
    "                    winning_method_em = soup.find('em', string='Method').parent\n",
    "                    winning_method = winning_method_em.contents[2].strip()\n",
    "                    winning_round_em = soup.find('em', string='Round').parent\n",
    "                    winning_round = winning_round_em.contents[2].strip()\n",
    "                    winning_time_em = soup.find('em', string='Time').parent\n",
    "                    winning_time = winning_time_em.contents[2].strip()\n",
    "                    referee_em = soup.find('em', string='Referee').parent\n",
    "                    referee = referee_em.find('a').text.strip()\n",
    "                    event_data.append({\n",
    "                        'Event Name': event_name,\n",
    "                        'Event Location': event_location,\n",
    "                        'Event Date': event_date,\n",
    "                        'Fighter 1': fighter1,\n",
    "                        'Fighter 2': fighter2,\n",
    "                        'Fighter 1 ID': fighter1_id,\n",
    "                        'Fighter 2 ID': fighter2_id,\n",
    "                        'Weight Class': weight_class,\n",
    "                        'Winning Fighter': winning_fighter,\n",
    "                        'Winning Method': winning_method,\n",
    "                        'Winning Round': winning_round,\n",
    "                        'Winning Time': winning_time,\n",
    "                        'Referee': referee,\n",
    "                        'Fight Type': 'Main Event'\n",
    "                    })\n",
    "                other_bouts = soup.find_all('tr', itemprop='subEvent')\n",
    "                for bout in other_bouts:\n",
    "                    fighters = bout.find_all('div', class_='fighter_list')\n",
    "                    if len(fighters) >= 2:\n",
    "                        fighter1 = fighters[0].find('img')['title']\n",
    "                        fighter2 = fighters[1].find('img')['title']\n",
    "                        fighter1_url = fighters[0].find('a', itemprop='url')['href']\n",
    "                        fighter2_url = fighters[1].find('a', itemprop='url')['href']\n",
    "                        fighter1_id = fighter1_url.split('-')[-1]\n",
    "                        fighter2_id = fighter2_url.split('-')[-1]\n",
    "                        weight_class = bout.find('span', class_='weight_class')\n",
    "                        weight_class = weight_class.text.strip() if weight_class else \"Unknown\"\n",
    "                        winning_method = bout.find('td', class_='winby').find('b').get_text(strip=True)\n",
    "                        winning_round = bout.find_all('td')[-2].get_text(strip=True)\n",
    "                        winning_time = bout.find_all('td')[-1].get_text(strip=True)\n",
    "                        referee = bout.find('td', class_='winby').find('a').get_text(strip=True)\n",
    "                        event_data.append({\n",
    "                            'Event Name': event_name,\n",
    "                            'Event Location': event_location,\n",
    "                            'Event Date': event_date,\n",
    "                            'Fighter 1': fighter1,\n",
    "                            'Fighter 2': fighter2,\n",
    "                            'Fighter 1 ID': fighter1_id,\n",
    "                            'Fighter 2 ID': fighter2_id,\n",
    "                            'Weight Class': weight_class,\n",
    "                            'Winning Fighter': fighter1,  \n",
    "                            'Winning Method': winning_method,\n",
    "                            'Winning Round': winning_round,\n",
    "                            'Winning Time': winning_time,\n",
    "                            'Referee': referee,\n",
    "                            'Fight Type': 'Undercard'\n",
    "                        })\n",
    "        return event_data\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed for {full_url}: {e}\")\n",
    "        return None\n",
    "session = requests.Session()\n",
    "total_urls = len(urls_df['Event_URL'])\n",
    "completed_requests = 0\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "    futures = [executor.submit(fetch_event_data, url, session) for url in urls_df['Event_URL']]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        data = future.result()\n",
    "        completed_requests += 1\n",
    "        progress_percentage = (completed_requests / total_urls) * 100\n",
    "        print(f\"Completed {completed_requests}/{total_urls} requests ({progress_percentage:.2f}%)\")\n",
    "        if data:\n",
    "            all_data.extend(data)\n",
    "df = pd.DataFrame(all_data)\n",
    "file_path = './data/event_data_sherdog.csv'\n",
    "write_mode = 'a' if os.path.isfile(file_path) else 'w'\n",
    "df.to_csv(file_path, mode=write_mode, header=not os.path.isfile(file_path), index=False)\n",
    "print(\"Data successfully written to data/event_data_sherdog.csv\")\n",
    "print(f\"Total number of rows: {len(df)}\")\n",
    "print(f\"Column names: {list(df.columns)}\")\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sherdog: Fighter IDs\n",
    "# fighter_id_sherdog.csv\n",
    "\n",
    "df = pd.read_csv('./data/event_data_sherdog.csv')\n",
    "df2 = pd.DataFrame(columns=['Fighter', 'Fighter_ID'])\n",
    "df2.to_csv('./data/fighter_id_sherdog.csv', index=False)\n",
    "for index, row in df.iterrows():\n",
    "    fighter1 = row['Fighter 1']\n",
    "    fighter2 = row['Fighter 2']\n",
    "    fighter1_id = row['Fighter 1 ID']\n",
    "    fighter2_id = row['Fighter 2 ID']\n",
    "    for fighter, fighter_id in zip([fighter1, fighter2], [fighter1_id, fighter2_id]):\n",
    "        if fighter not in df2['Fighter'].values and fighter_id not in df2['Fighter_ID'].values:\n",
    "            df2 = pd.concat([df2, pd.DataFrame([{'Fighter': fighter, 'Fighter_ID': fighter_id}])])  # adjusted line\n",
    "df2.to_csv('./data/fighter_id_sherdog.csv', index=False)\n",
    "print(\"Data successfully written to data/fighter_id_sherdog.csv\")\n",
    "print(f\"Total number of rows: {len(df2)}\")\n",
    "print(f\"Column names: {list(df2.columns)}\")\n",
    "\n",
    "# Remove nicknames\n",
    "# df = pd.read_csv('./data/fighter_id_sherdog.csv')\n",
    "# df['Fighter'] = df['Fighter'].str.replace(r\" '.+?'\", \"\", regex=True)\n",
    "# df.to_csv('./data/fighter_id_sherdog.csv', index=False)\n",
    "# df = pd.read_csv('./data/event_data_sherdog.csv')\n",
    "# for col in ['Fighter 1', 'Fighter 2', 'Winning Fighter']:\n",
    "#     df[col] = df[col].str.replace(r\" '.+?'\", \"\", regex=True)\n",
    "# df.to_csv('./data/event_data_sherdog.csv', index=False)\n",
    "\n",
    "# Add 'UFC' indicator to current fighters in fighter_id_sherdog.csv.csv\n",
    "df = pd.read_csv('./data/fighter_id_sherdog.csv')\n",
    "df['UFC'] = 'y'\n",
    "df.to_csv('./data/fighter_id_sherdog.csv', index=False)\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df.to_csv('./data/fighter_id_sherdog.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sherdog: Fighter Info\n",
    "# fighter_info.csv\n",
    "\n",
    "def scrape_fighter_general_info_sherdog(fighter, fighter_id):\n",
    "    url = f'https://www.sherdog.com/fighter/{fighter_id}'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return {}\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    fighter_dict = {}\n",
    "    try:\n",
    "        fighter_data = soup.find('div', class_='fighter-data')\n",
    "    except AttributeError:\n",
    "        fighter_data = None\n",
    "    try:\n",
    "        birthdate = soup.find('span', itemprop='birthDate')\n",
    "        birthdate = (birthdate.text).strip('\"\"')\n",
    "    except AttributeError:\n",
    "        birthdate = '-'\n",
    "    try:\n",
    "        nationality = soup.find('strong', itemprop='nationality')\n",
    "        nationality = (nationality.text).strip()\n",
    "    except AttributeError:\n",
    "        nationality = '-'\n",
    "    try:\n",
    "        hometown = soup.find('span', {'itemprop': 'addressLocality'}).text\n",
    "        hometown = hometown.strip()\n",
    "    except AttributeError:\n",
    "        hometown = '-'\n",
    "    try:\n",
    "        association = soup.find('span', {'itemprop': 'name'}).text\n",
    "        association = association.strip()\n",
    "    except AttributeError:\n",
    "        association = '-'\n",
    "    try:\n",
    "        weight_class_div = fighter_data.find('div', {'class': 'association-class'})\n",
    "        links = weight_class_div.find_all('a')\n",
    "        weight_class = links[-1].text\n",
    "        weight_class = weight_class.strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        weight_class = ''\n",
    "    try:\n",
    "        nickname = soup.find('span', class_='nickname')\n",
    "        nickname = (nickname.text).strip('\"')\n",
    "    except AttributeError:\n",
    "        nickname = '-'\n",
    "    try:\n",
    "        height = soup.find('b', itemprop='height')\n",
    "        height = (height.text).strip('\"')\n",
    "    except AttributeError:\n",
    "        height = '-'\n",
    "    try:\n",
    "        wins = soup.find('div', class_='winloses win').find_all('span')[1]\n",
    "        wins = (wins.text).strip()\n",
    "    except AttributeError:\n",
    "        wins = '-'\n",
    "    try:\n",
    "        losses = soup.find('div', class_='winloses lose').find_all('span')[1]\n",
    "        losses = (losses.text).strip()\n",
    "    except AttributeError:\n",
    "        losses = '-'\n",
    "    dec_data_list = []\n",
    "    try:\n",
    "        win_type = fighter_data.find_all('div', class_='meter-title', string='DECISIONS')\n",
    "        for method in win_type:\n",
    "            if method.text.startswith('DECISIONS'):\n",
    "                dec_data = method.find_next('div', class_='pl').text\n",
    "                dec_data_list.append(dec_data)\n",
    "        wins_dec = (dec_data_list[0]).strip()\n",
    "        losses_dec = (dec_data_list[1]).strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        wins_dec = '-'\n",
    "        losses_dec = '-'\n",
    "    ko_data_list = []\n",
    "    try:\n",
    "        win_type = soup.find_all('div', class_='meter-title')\n",
    "        for method in win_type:\n",
    "            if method.text.startswith('KO'):\n",
    "                ko_data = method.find_next('div', class_='pl').text\n",
    "                ko_data_list.append(ko_data)\n",
    "        wins_ko = (ko_data_list[0]).strip()\n",
    "        losses_ko = (ko_data_list[1]).strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        wins_ko = '-'\n",
    "        losses_ko = '-'\n",
    "    sub_data_list = []\n",
    "    try:\n",
    "        win_type = fighter_data.find_all('div', class_='meter-title', string='SUBMISSIONS')\n",
    "        for method in win_type:\n",
    "            if method.text.startswith('SUBMISSIONS'):\n",
    "                sub_data = method.find_next('div', class_='pl').text\n",
    "                sub_data_list.append(sub_data)\n",
    "        wins_sub = (sub_data_list[0]).strip()\n",
    "        losses_sub = (sub_data_list[1]).strip()\n",
    "    except (AttributeError, IndexError):\n",
    "        wins_sub = '-'\n",
    "        losses_sub = '-'\n",
    "    fighter_dict = {\n",
    "        'Fighter': fighter,\n",
    "        'Nickname': nickname,\n",
    "        'Birth Date': birthdate,\n",
    "        'Nationality': nationality,\n",
    "        'Hometown': hometown,\n",
    "        'Association': association,\n",
    "        'Weight Class': weight_class,\n",
    "        'Height': height,\n",
    "        'Wins': wins,\n",
    "        'Losses': losses,\n",
    "        'Win_Decision': wins_dec,\n",
    "        'Win_KO': wins_ko,\n",
    "        'Win_Sub': wins_sub,\n",
    "        'Loss_Decision': losses_dec,\n",
    "        'Loss_KO': losses_ko,\n",
    "        'Loss_Sub': losses_sub,\n",
    "        'Fighter_ID': fighter_id\n",
    "    }\n",
    "    return fighter_dict\n",
    "\n",
    "def scrape_fighters_concurrently():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    df_fighter_id = pd.read_csv('./data/fighter_id_sherdog.csv')\n",
    "    fighter_data_list = []\n",
    "    total_fighters = len(df_fighter_id)\n",
    "    fighters_processed = 0\n",
    "    with ThreadPoolExecutor(max_workers=30) as executor:\n",
    "        future_to_fighter = {executor.submit(scrape_fighter_general_info_sherdog, row['Fighter'], row['Fighter_ID']): row for index, row in df_fighter_id.iterrows()}\n",
    "        for future in tqdm.tqdm(as_completed(future_to_fighter), total=len(future_to_fighter)):\n",
    "            fighter_data = future.result()\n",
    "            if fighter_data:\n",
    "                fighter_data_list.append(fighter_data)\n",
    "            fighters_processed += 1\n",
    "            print(f\"Scraping Fighter Info: {fighters_processed}/{total_fighters} fighters processed\")\n",
    "    new_df = pd.DataFrame(fighter_data_list)\n",
    "    new_df.to_csv('./data/fighter_info.csv', index=False)\n",
    "scrape_fighters_concurrently()\n",
    "\n",
    "df = pd.read_csv('./data/fighter_info.csv')\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df.to_csv('./data/fighter_info.csv', index=False)\n",
    "print(\"Data successfully written to data/fighter_info.csv\")\n",
    "print(f\"Total number of rows: {len(df)}\")\n",
    "print(f\"Column names: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sherdog: Fighters\n",
    "# data/fighters/*\n",
    "\n",
    "os.makedirs('./data/fighters/')\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "def scrape_fighter_fights_sherdog(fighter_name, fighter_id, fighter_url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "    response = requests.get(fighter_url, headers=headers, timeout=60)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'new_table fighter'})\n",
    "        rows = table.find_all('tr')[1:]\n",
    "        fight_data = []\n",
    "        new_opponents = []\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            fight_dict = {\n",
    "                'Result': cols[0].text.strip(),\n",
    "                'Opponent': cols[1].find('a').text.strip() if cols[1].find('a') else '-',\n",
    "                'Event Date': cols[2].find_all('span')[-1].text.strip() if cols[2].find_all('span') else '-',\n",
    "                'Method/Referee': cols[3].text.strip().split('\\n')[0],\n",
    "                'Rounds': cols[4].text.strip(),\n",
    "                'Time': cols[5].text.strip()\n",
    "            }\n",
    "            fight_data.append(fight_dict)\n",
    "            opponent_link = cols[1].find('a')['href'] if cols[1].find('a') else None\n",
    "            if opponent_link:\n",
    "                opponent_id = opponent_link.split('-')[-1]\n",
    "                new_opponents.append({'Fighter': fight_dict['Opponent'], 'Fighter_ID': opponent_id})\n",
    "        return fighter_id, fighter_name, fight_data, new_opponents\n",
    "    return fighter_id, fighter_name, [], []\n",
    "df_fighter_id = pd.read_csv('./data/fighter_id_sherdog.csv')\n",
    "all_new_opponents = []\n",
    "def process_fighter(row):\n",
    "    fighter_url = f\"https://www.sherdog.com/fighter/{row['Fighter'].replace(' ', '-')}-{row['Fighter_ID']}\"\n",
    "    return scrape_fighter_fights_sherdog(row['Fighter'], row['Fighter_ID'], fighter_url)\n",
    "total_fighters = len(df_fighter_id)\n",
    "fighters_processed = 0\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_fighter, row) for _, row in df_fighter_id.iterrows()]\n",
    "    for future in as_completed(futures):\n",
    "        fighter_id, fighter_name, fight_data, new_opponents = future.result()\n",
    "        fighters_processed += 1\n",
    "        print(f\"Processed {fighters_processed}/{total_fighters} fighters: {fighter_name}\")\n",
    "        if fight_data:\n",
    "            pd.DataFrame(fight_data).to_csv(f\"./data/fighters/{fighter_name.replace(' ', '_')}_{fighter_id}.csv\", index=False)\n",
    "            all_new_opponents.extend(new_opponents)\n",
    "if all_new_opponents:\n",
    "    df_new_opponents = pd.DataFrame(all_new_opponents).drop_duplicates()\n",
    "    df_fighter_id = pd.concat([df_fighter_id, df_new_opponents], ignore_index=True).drop_duplicates()\n",
    "    df_fighter_id.to_csv('./data/fighter_id_sherdog.csv', index=False)\n",
    "\n",
    "directory_path = './data/fighters/'\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "first_name = \"Dustin\"\n",
    "last_name = \"Poirier\"\n",
    "file_pattern = f'./data/fighters/*{first_name}*{last_name}*.csv'\n",
    "matching_files = glob.glob(file_pattern)\n",
    "if matching_files:\n",
    "    first_file = matching_files[0]\n",
    "    df = pd.read_csv(first_file)\n",
    "    print(f\"Total number of rows including the header in {first_file}: {len(df)}\")\n",
    "    print(f\"Column names: {list(df.columns)}\")\n",
    "else:\n",
    "    print(\"No files found matching the pattern.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sherdog: Cleaning\n",
    "\n",
    "fighter_info_df = pd.read_csv('./data/fighter_info.csv')\n",
    "event_data_df = pd.read_csv('./data/event_data_sherdog.csv')\n",
    "print(f\"Number of rows in fighter_info.csv: {len(fighter_info_df)}\")\n",
    "print(f\"Number of rows in event_data_sherdog.csv: {len(event_data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open data/fighter_info.csv\n",
    "!open data/event_data_sherdog.csv\n",
    "!open data/reach_dictionary.csv\n",
    "!open data/github/master.csv\n",
    "!open data/github/ufc_fighter_tott.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
