{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download github data\n",
    "\n",
    "shutil.rmtree('./data')  # Remove the directory and all its contents\n",
    "os.mkdir('./data')\n",
    "os.makedirs('./data/github/', exist_ok=True)\n",
    "urls = [\n",
    "    'https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/main/ufc_event_details.csv',\n",
    "    'https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/main/ufc_fight_results.csv',\n",
    "    #'https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/main/ufc_fight_details.csv',\n",
    "    #'https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/main/ufc_fight_stats.csv',\n",
    "    #'https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/main/ufc_fighter_details.csv',\n",
    "    'https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/main/ufc_fighter_tott.csv'\n",
    "]\n",
    "for url in urls:\n",
    "    filename = os.path.join('./data/github/', url.split('/')[-1])\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {url}\")\n",
    "for url in urls:\n",
    "    filename = os.path.join('./data/github/', url.split('/')[-1])\n",
    "    df = pd.read_csv(filename)\n",
    "    print(f\"Total rows in {filename}: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape fighter pages from ufcstats.com\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "})\n",
    "df = pd.read_csv('./data/github/ufc_fighter_tott.csv')\n",
    "print(f\"Loaded {len(df)} fighters from CSV\")\n",
    "fighter_details = []\n",
    "failed_fighters = []\n",
    "details_lock = Lock()\n",
    "failed_lock = Lock()\n",
    "counter_lock = Lock()\n",
    "completed_count = 0\n",
    "def scrape_fighter(fighter_info):\n",
    "    \"\"\"Scrape a single fighter's details - thread-safe function\"\"\"\n",
    "    global completed_count\n",
    "    index, fighter_name, fighter_url = fighter_info\n",
    "    try:\n",
    "        response = session.get(fighter_url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        fighter_data = {\n",
    "            'name': fighter_name,\n",
    "            'url': fighter_url,\n",
    "            'height': '', 'weight': '', 'reach': '', 'stance': '', 'dob': '',\n",
    "            'slpm': '', 'str_acc': '', 'sapm': '', 'str_def': '',\n",
    "            'td_avg': '', 'td_acc': '', 'td_def': '', 'sub_avg': ''\n",
    "        }\n",
    "        info_boxes = soup.find_all('div', class_='b-list__info-box')\n",
    "        for info_box in info_boxes:\n",
    "            list_items = info_box.find_all('li', class_='b-list__box-list-item')\n",
    "            for item in list_items:\n",
    "                title_elem = item.find('i', class_='b-list__box-item-title')\n",
    "                if title_elem:\n",
    "                    title = title_elem.text.strip().lower().replace(':', '')\n",
    "                    value = item.get_text().replace(title_elem.get_text(), '').strip()\n",
    "                    if 'height' in title:\n",
    "                        fighter_data['height'] = value\n",
    "                    elif 'weight' in title:\n",
    "                        fighter_data['weight'] = value\n",
    "                    elif 'reach' in title:\n",
    "                        fighter_data['reach'] = value\n",
    "                    elif 'stance' in title:\n",
    "                        fighter_data['stance'] = value\n",
    "                    elif 'dob' in title:\n",
    "                        fighter_data['dob'] = value\n",
    "                    elif 'slpm' in title:\n",
    "                        fighter_data['slpm'] = value\n",
    "                    elif 'str. acc' in title:\n",
    "                        fighter_data['str_acc'] = value\n",
    "                    elif 'sapm' in title:\n",
    "                        fighter_data['sapm'] = value\n",
    "                    elif 'str. def' in title:\n",
    "                        fighter_data['str_def'] = value\n",
    "                    elif 'td avg' in title:\n",
    "                        fighter_data['td_avg'] = value\n",
    "                    elif 'td acc' in title:\n",
    "                        fighter_data['td_acc'] = value\n",
    "                    elif 'td def' in title:\n",
    "                        fighter_data['td_def'] = value\n",
    "                    elif 'sub. avg' in title:\n",
    "                        fighter_data['sub_avg'] = value\n",
    "        for key, value in fighter_data.items():\n",
    "            if value == '--':\n",
    "                fighter_data[key] = ''\n",
    "        with details_lock:\n",
    "            fighter_details.append(fighter_data)\n",
    "        with counter_lock:\n",
    "            completed_count += 1\n",
    "            if completed_count % 100 == 0 or completed_count <= 20:\n",
    "                print(f\"✓ Progress: {completed_count}/{len(df)} - Latest: {fighter_name}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        with failed_lock:\n",
    "            failed_fighters.append({'name': fighter_name, 'url': fighter_url, 'error': str(e)})\n",
    "        with counter_lock:\n",
    "            completed_count += 1\n",
    "            if completed_count <= 20:  \n",
    "                print(f\"✗ Failed: {fighter_name} - {str(e)}\")\n",
    "        return False\n",
    "fighter_list = [(index, row['FIGHTER'], row['URL']) for index, row in df.iterrows()]\n",
    "print(f\"Starting FAST parallel scraping with 10 threads...\")\n",
    "start_time = time.time()\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(scrape_fighter, fighter_info) for fighter_info in fighter_list]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()  \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\n=== FAST SCRAPING COMPLETED ===\")\n",
    "print(f\"Total time: {elapsed_time:.1f} seconds ({elapsed_time/60:.1f} minutes)\")\n",
    "print(f\"Successfully scraped: {len(fighter_details)} fighters\")\n",
    "print(f\"Failed: {len(failed_fighters)} fighters\")\n",
    "print(f\"Success rate: {len(fighter_details)}/{len(df)} ({len(fighter_details)/len(df)*100:.1f}%)\")\n",
    "print(f\"Average time per fighter: {elapsed_time/len(df):.3f} seconds\")\n",
    "if fighter_details:\n",
    "    fieldnames = [\n",
    "        'name', 'url', 'height', 'weight', 'reach', 'stance', 'dob',\n",
    "        'slpm', 'str_acc', 'sapm', 'str_def', 'td_avg', 'td_acc', 'td_def', 'sub_avg'\n",
    "    ]\n",
    "    with open('./data/fighters.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(fighter_details)\n",
    "    print(f\"✓ Saved {len(fighter_details)} fighter details to ./data/fighters.csv\")\n",
    "else:\n",
    "    print(\"No fighter details to save\")\n",
    "    \n",
    "# Display summary and sample data\n",
    "if fighter_details:\n",
    "    df_results = pd.DataFrame(fighter_details)\n",
    "    print(\"=== SCRAPING SUMMARY ===\")\n",
    "    print(f\"Total fighters scraped: {len(df_results)}\")\n",
    "    print(f\"Total columns: {len(df_results.columns)}\")\n",
    "    print(f\"Success rate: {len(fighter_details)}/{len(df)} ({len(fighter_details)/len(df)*100:.1f}%)\")\n",
    "    print(\"\\n=== COLUMN ANALYSIS ===\")\n",
    "    for col in df_results.columns:\n",
    "        missing_count = (df_results[col] == '').sum()\n",
    "        missing_pct = (missing_count / len(df_results)) * 100\n",
    "        print(f\"{col}: {missing_count} missing ({missing_pct:.1f}%)\")\n",
    "    print(f\"\\n=== SAMPLE DATA (First 3 fighters) ===\")\n",
    "    print(df_results.head(3).to_string())\n",
    "    if failed_fighters:\n",
    "        print(f\"\\n=== FAILED FIGHTERS ===\")\n",
    "        for fighter in failed_fighters:\n",
    "            print(f\"- {fighter['name']}: {fighter['error']}\")\n",
    "else:\n",
    "    print(\"No data scraped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all events before 2010 from ufc_fight_results.csv\n",
    "\n",
    "import pandas as pd\n",
    "print('=== CLEANING FIGHT RESULTS - REMOVING PRE-2010 EVENTS ===')\n",
    "fight_results_df = pd.read_csv('./data/github/ufc_fight_results.csv')\n",
    "events_df = pd.read_csv('./data/github/ufc_event_details.csv')\n",
    "print(f'Original fight results count: {len(fight_results_df)}')\n",
    "fight_results_df['EVENT'] = fight_results_df['EVENT'].str.strip()\n",
    "events_df['DATE_PARSED'] = pd.to_datetime(events_df['DATE'], format='%B %d, %Y')\n",
    "events_before_2010 = events_df[events_df['DATE_PARSED'] < '2010-01-01']\n",
    "event_names_to_remove = events_before_2010['EVENT'].tolist()\n",
    "print(f'Events before 2010 to remove: {len(event_names_to_remove)}')\n",
    "matching_events = set(event_names_to_remove) & set(fight_results_df['EVENT'].unique())\n",
    "print(f'Matching events found: {len(matching_events)}')\n",
    "if len(matching_events) > 0:\n",
    "    print(f'Removing fights from {len(matching_events)} events...')\n",
    "    fights_before_removal = len(fight_results_df)\n",
    "    fight_results_cleaned = fight_results_df[~fight_results_df['EVENT'].isin(matching_events)]\n",
    "    fights_after_removal = len(fight_results_cleaned)\n",
    "    print(f'Fights removed: {fights_before_removal - fights_after_removal}')\n",
    "    print(f'Remaining fights: {fights_after_removal}')\n",
    "    fight_results_cleaned.to_csv('./data/github/ufc_fight_results.csv', index=False)\n",
    "    print('✓ Saved cleaned fight results to ./data/github/ufc_fight_results.csv')\n",
    "    fight_results_df.to_csv('./data/github/ufc_fight_results_backup.csv', index=False)\n",
    "    print('✓ Created backup at ./data/github/ufc_fight_results_backup.csv')\n",
    "    fight_events_in_details = events_df[events_df['EVENT'].isin(fight_results_cleaned['EVENT'].unique())]\n",
    "    if len(fight_events_in_details) > 0:\n",
    "        fight_events_in_details['DATE_PARSED'] = pd.to_datetime(fight_events_in_details['DATE'], format='%B %d, %Y')\n",
    "        earliest = fight_events_in_details['DATE_PARSED'].min()\n",
    "        latest = fight_events_in_details['DATE_PARSED'].max()\n",
    "        print(f'New date range: {earliest.strftime(\"%Y-%m-%d\")} to {latest.strftime(\"%Y-%m-%d\")}')\n",
    "        before_2010_remaining = fight_events_in_details[fight_events_in_details['DATE_PARSED'] < '2010-01-01']\n",
    "        if len(before_2010_remaining) == 0:\n",
    "            print('✅ SUCCESS: All events before 2010 have been removed!')\n",
    "        else:\n",
    "            print(f'⚠️ WARNING: {len(before_2010_remaining)} events before 2010 still remain')\n",
    "else:\n",
    "    print('❌ No matching events found - the fight results may already be filtered to post-2010 events')\n",
    "    \n",
    "    \n",
    "\n",
    "# Delete all fighters before 2010 in fighters.csv\n",
    "print('=== FILTERING FIGHTER INFO TO MATCH POST-2010 FIGHTS ===')\n",
    "fight_results_df = pd.read_csv('./data/github/ufc_fight_results.csv')\n",
    "fighter_info_df = pd.read_csv('./data/fighters.csv')\n",
    "print(f'Fight results count: {len(fight_results_df)}')\n",
    "print(f'Fighter info count: {len(fighter_info_df)}')\n",
    "all_fighters_in_bouts = []\n",
    "for bout in fight_results_df['BOUT']:\n",
    "    if ' vs. ' in bout:\n",
    "        fighters = bout.split(' vs. ')\n",
    "        if len(fighters) == 2:\n",
    "            all_fighters_in_bouts.extend([fighters[0].strip(), fighters[1].strip()])\n",
    "unique_fighters_post_2010 = set(all_fighters_in_bouts)\n",
    "print(f'Unique fighters in post-2010 fights: {len(unique_fighters_post_2010)}')\n",
    "fighter_info_df['name_lower'] = fighter_info_df['name'].str.lower()\n",
    "unique_fighters_lower = {name.lower() for name in unique_fighters_post_2010}\n",
    "fighter_info_filtered = fighter_info_df[fighter_info_df['name_lower'].isin(unique_fighters_lower)]\n",
    "fighter_info_filtered = fighter_info_filtered.drop('name_lower', axis=1)\n",
    "print(f'Fighters before filtering: {len(fighter_info_df)}')\n",
    "print(f'Fighters after filtering: {len(fighter_info_filtered)}')\n",
    "print(f'Fighters removed: {len(fighter_info_df) - len(fighter_info_filtered)}')\n",
    "fighter_info_filtered.to_csv('./data/fighters.csv', index=False)\n",
    "print('✓ Saved filtered fighter info to ./data/fighters.csv')\n",
    "print(f'Retention rate: {len(fighter_info_filtered)/len(fighter_info_df)*100:.1f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all women fighters from fighters.csv\n",
    "\n",
    "print('\\n=== REMOVING WOMEN FIGHTERS FROM FIGHTER INFO ===')\n",
    "fight_results_df = pd.read_csv('./data/github/ufc_fight_results.csv')\n",
    "fighter_info_df = pd.read_csv('./data/fighters.csv')\n",
    "print(f'Original fighter info count: {len(fighter_info_df)}')\n",
    "womens_weight_classes = fight_results_df[fight_results_df['WEIGHTCLASS'].str.contains('Women\\'s', na=False)]['WEIGHTCLASS'].unique()\n",
    "print(f'Women\\'s weight classes found: {len(womens_weight_classes)}')\n",
    "for wc in womens_weight_classes:\n",
    "    print(f'  - {wc}')\n",
    "women_fighters_in_bouts = []\n",
    "womens_fights = fight_results_df[fight_results_df['WEIGHTCLASS'].str.contains('Women\\'s', na=False)]\n",
    "print(f'Total women\\'s fights found: {len(womens_fights)}')\n",
    "for bout in womens_fights['BOUT']:\n",
    "    if ' vs. ' in bout:\n",
    "        fighters = bout.split(' vs. ')\n",
    "        if len(fighters) == 2:\n",
    "            women_fighters_in_bouts.extend([fighters[0].strip(), fighters[1].strip()])\n",
    "unique_women_fighters = set(women_fighters_in_bouts)\n",
    "print(f'Unique women fighters found: {len(unique_women_fighters)}')\n",
    "fighter_info_df['name_lower'] = fighter_info_df['name'].str.lower()\n",
    "women_fighters_lower = {name.lower() for name in unique_women_fighters}\n",
    "fighter_info_men_only = fighter_info_df[~fighter_info_df['name_lower'].isin(women_fighters_lower)]\n",
    "fighter_info_men_only = fighter_info_men_only.drop('name_lower', axis=1)\n",
    "print(f'Fighters before removing women: {len(fighter_info_df)}')\n",
    "print(f'Fighters after removing women: {len(fighter_info_men_only)}')\n",
    "print(f'Women fighters removed: {len(fighter_info_df) - len(fighter_info_men_only)}')\n",
    "fighter_info_men_only.to_csv('./data/fighters.csv', index=False)\n",
    "print('✓ Saved men-only fighter info to ./data/fighters.csv')\n",
    "fighter_info_df.drop('name_lower', axis=1).to_csv('./data/fighter_info_with_women_backup.csv', index=False)\n",
    "print('✓ Created backup with women fighters at ./data/fighter_info_with_women_backup.csv')\n",
    "print(f'Retention rate: {len(fighter_info_men_only)/len(fighter_info_df)*100:.1f}%')\n",
    "print(f'\\nSample of removed women fighters:')\n",
    "removed_women = list(unique_women_fighters)[:10]\n",
    "for fighter in removed_women:\n",
    "    print(f'  - {fighter}')\n",
    "if len(unique_women_fighters) > 10:\n",
    "    print(f'  ... and {len(unique_women_fighters) - 10} more')\n",
    "print('\\n✅ SUCCESS: All women fighters have been removed from fighters.csv!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in fighters.csv and remove rows with missing reach/height/stance\n",
    "\n",
    "print('\\n=== CHECKING FOR MISSING VALUES IN FIGHTER INFO ===')\n",
    "fighter_info_df = pd.read_csv('./data/fighters.csv')\n",
    "print(f'Total fighters before cleaning: {len(fighter_info_df)}')\n",
    "missing_values = fighter_info_df.isna().sum()\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values\n",
    "})\n",
    "print('\\nMissing values by column:')\n",
    "print(missing_df)\n",
    "empty_strings = (fighter_info_df == '').sum()\n",
    "if empty_strings.sum() > 0:\n",
    "    print('\\nEmpty strings by column:')\n",
    "    print(empty_strings[empty_strings > 0])\n",
    "else:\n",
    "    print('\\nNo columns have more than 5% missing values.')\n",
    "print('\\nRows with missing reach values:')\n",
    "missing_reach_df = fighter_info_df[fighter_info_df['reach'].isna()]\n",
    "print(missing_reach_df)\n",
    "print(f'Total rows with missing reach: {len(missing_reach_df)}')\n",
    "fighter_info_df = fighter_info_df.dropna(subset=['reach'])\n",
    "print(f'\\nTotal fighters after removing rows with missing reach: {len(fighter_info_df)}')\n",
    "print(f'Removed {len(missing_reach_df)} fighters with missing reach data')\n",
    "fighter_info_df.to_csv('./data/fighters.csv', index=False)\n",
    "print('✓ Saved cleaned fighter info to ./data/fighters.csv')\n",
    "print('\\nMissing values in each column after cleaning:')\n",
    "print(fighter_info_df.isna().sum())\n",
    "print('\\nRows with missing values:')\n",
    "missing_rows = fighter_info_df[fighter_info_df.isna().any(axis=1)]\n",
    "print(missing_rows.to_string())\n",
    "print(f'Total rows with missing values: {len(missing_rows)}')\n",
    "fighter_info_df = fighter_info_df.dropna()\n",
    "fighter_info_df.to_csv('./data/fighters.csv', index=False)\n",
    "print(f'\\nRemoved all rows with any missing values. Final count: {len(fighter_info_df)}')\n",
    "print('✓ Saved final cleaned fighter info to ./data/fighters.csv')\n",
    "print('\\n✅ Missing values analysis complete and all rows with missing values removed!')\n",
    "print('\\nRows with missing values:')\n",
    "missing_rows = fighter_info_df[fighter_info_df.isna().any(axis=1)]\n",
    "print(missing_rows.to_string())\n",
    "print(f'Total rows with missing values: {len(missing_rows)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean fights.csv master file from fight results data\n",
    "\n",
    "print('=== CREATING CLEAN FIGHTS.CSV MASTER FILE ===')\n",
    "fight_results_df = pd.read_csv('./data/github/ufc_fight_results.csv')\n",
    "print(f'Original fight results count: {len(fight_results_df)}')\n",
    "print('\\n--- Removing Women\\'s Fights ---')\n",
    "womens_fights = fight_results_df[fight_results_df['WEIGHTCLASS'].str.contains('Women\\'s', na=False)]\n",
    "print(f'Women\\'s fights to remove: {len(womens_fights)}')\n",
    "fights_men_only = fight_results_df[~fight_results_df['WEIGHTCLASS'].str.contains('Women\\'s', na=False)]\n",
    "print(f'Fights after removing women: {len(fights_men_only)}')\n",
    "print(f'Women\\'s fights removed: {len(fight_results_df) - len(fights_men_only)}')\n",
    "print('\\n--- Extracting Fighter Names ---')\n",
    "fights_clean = fights_men_only.copy()\n",
    "print('Extracting fighter names from BOUT column...')\n",
    "fights_clean['FIGHTER_1'] = ''\n",
    "fights_clean['FIGHTER_2'] = ''\n",
    "for idx, bout in enumerate(fights_clean['BOUT']):\n",
    "    if ' vs. ' in bout:\n",
    "        fighters = bout.split(' vs. ')\n",
    "        if len(fighters) == 2:\n",
    "            fights_clean.loc[fights_clean.index[idx], 'FIGHTER_1'] = fighters[0].strip()\n",
    "            fights_clean.loc[fights_clean.index[idx], 'FIGHTER_2'] = fighters[1].strip()\n",
    "final_columns = [\n",
    "    'EVENT', 'BOUT', 'FIGHTER_1', 'FIGHTER_2', 'OUTCOME', \n",
    "    'WEIGHTCLASS', 'METHOD', 'ROUND', 'TIME', 'TIME FORMAT', \n",
    "    'REFEREE', 'DETAILS', 'URL'\n",
    "]\n",
    "fights_master = fights_final[final_columns].copy()\n",
    "fights_master = fights_master.sort_values(['EVENT', 'BOUT']).reset_index(drop=True)\n",
    "fights_master.to_csv('./data/fights.csv', index=False)\n",
    "print(f'✓ Saved {len(fights_master)} fights to ./data/fights.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary statistics and verification\n",
    "#print('\\n=== FIGHTS.CSV MASTER FILE SUMMARY ===')\n",
    "#print(f'Total fights in master file: {len(fights_master)}')\n",
    "#print(f'Original fight results: {len(fight_results_df)}')\n",
    "#print(f'Fights removed: {len(fight_results_df) - len(fights_master)}')\n",
    "#print(f'Retention rate: {len(fights_master)/len(fight_results_df)*100:.1f}%')\n",
    "#print('\\nWeight class distribution:')\n",
    "#print(fights_master['WEIGHTCLASS'].value_counts().head(10))\n",
    "#print('\\nMethod distribution:')  \n",
    "#print(fights_master['METHOD'].value_counts().head(10))\n",
    "#print('\\nOutcome distribution:')\n",
    "#print(fights_master['OUTCOME'].value_counts())\n",
    "#print('\\nDate range verification:')\n",
    "#unique_events = fights_master['EVENT'].nunique()\n",
    "#print(f'Total unique events: {unique_events}')\n",
    "#events_df = pd.read_csv('./data/github/ufc_event_details.csv')\n",
    "#events_df['DATE_PARSED'] = pd.to_datetime(events_df['DATE'], format='%B %d, %Y')\n",
    "#fight_events = events_df[events_df['EVENT'].isin(fights_master['EVENT'].unique())]\n",
    "#if len(fight_events) > 0:\n",
    "#    earliest = fight_events['DATE_PARSED'].min()\n",
    "#    latest = fight_events['DATE_PARSED'].max()\n",
    "#    print(f'Event date range: {earliest.strftime(\"%Y-%m-%d\")} to {latest.strftime(\"%Y-%m-%d\")}')\n",
    "#    pre_2010 = fight_events[fight_events['DATE_PARSED'] < '2010-01-01']\n",
    "#    if len(pre_2010) == 0:\n",
    "#        print('✅ Confirmed: No pre-2010 events in dataset')\n",
    "#    else:\n",
    "#        print(f'⚠️ Warning: {len(pre_2010)} pre-2010 events found')\n",
    "#print('\\n✅ SUCCESS: Clean fights.csv master file created!')\n",
    "#print(f'File location: ./data/fights.csv')\n",
    "#print(f'Total fights: {len(fights_master)}')\n",
    "#print(f'Total columns: {len(fights_master.columns)}')\n",
    "#print('\\n=== SAMPLE DATA (First 5 fights) ===')\n",
    "#print(fights_master.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
